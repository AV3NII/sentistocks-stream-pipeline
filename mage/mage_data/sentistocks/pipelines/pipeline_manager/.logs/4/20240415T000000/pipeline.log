2024-04-15T08:12:53 {"cpu": 0.7080078125, "cpu_total": 8, "cpu_usage": 0.0885009765625, "memory": 1265.0, "memory_total": 4802.0, "memory_usage": 0.26343190337359434, "pipeline_run_id": 90, "pipeline_schedule_id": 4, "pipeline_uuid": "pipeline_manager", "hostname": "56b0cc6559da", "level": "INFO", "message": "Pipeline pipeline_manager for run 90 in schedule 4 is alive.", "timestamp": 1713168773.194851, "uuid": "bd068aaf4d5a48d4ae2cd14dd010f8bb"}
2024-04-15T08:12:54 {"cpu": 0.7080078125, "cpu_total": 8, "cpu_usage": 0.0885009765625, "memory": 1350.0, "memory_total": 4802.0, "memory_usage": 0.2811328613077884, "pipeline_run_id": 90, "pipeline_schedule_id": 4, "pipeline_uuid": "pipeline_manager", "hostname": "56b0cc6559da", "level": "INFO", "message": "Pipeline pipeline_manager for run 90 in schedule 4 is alive.", "timestamp": 1713168774.506262, "uuid": "2a04539f43564b95b8f05d421d248dc0"}
2024-04-15T08:12:54 {"block_run_id": 344, "block_uuid": "load_bigquery_state", "pipeline_run_id": 90, "pipeline_schedule_id": 4, "pipeline_uuid": "pipeline_manager", "hostname": "56b0cc6559da", "level": "INFO", "message": "Execute PipelineRun 90, BlockRun 344: pipeline pipeline_manager block load_bigquery_state", "timestamp": 1713168774.829385, "uuid": "722e0de573f545c7822f8e41c231cadb"}
2024-04-15T08:13:02 {"cpu": 0.7705078125, "cpu_total": 8, "cpu_usage": 0.0963134765625, "memory": 1510.0, "memory_total": 4802.0, "memory_usage": 0.31445231153685965, "pipeline_run_id": 90, "pipeline_schedule_id": 4, "pipeline_uuid": "pipeline_manager", "hostname": "56b0cc6559da", "level": "INFO", "message": "Pipeline pipeline_manager for run 90 in schedule 4 is alive.", "timestamp": 1713168782.670096, "uuid": "99933e8f03694589a5a3b4bf32d9b769"}
2024-04-15T08:13:10 {"block_run_id": 344, "block_uuid": "load_bigquery_state", "pipeline_run_id": 90, "pipeline_schedule_id": 4, "pipeline_uuid": "pipeline_manager", "hostname": "56b0cc6559da", "level": "INFO", "message": "BlockRun 344 (block_uuid: load_bigquery_state) completes.", "timestamp": 1713168790.650519, "uuid": "0c30de325a40482da20ac3162230a2af"}
2024-04-15T08:13:12 {"cpu": 0.8056640625, "cpu_total": 8, "cpu_usage": 0.1007080078125, "memory": 1423.0, "memory_total": 4802.0, "memory_usage": 0.2963348604748022, "pipeline_run_id": 90, "pipeline_schedule_id": 4, "pipeline_uuid": "pipeline_manager", "hostname": "56b0cc6559da", "level": "INFO", "message": "Pipeline pipeline_manager for run 90 in schedule 4 is alive.", "timestamp": 1713168792.816757, "uuid": "1d2b826e6ee449eca85c6659bf286c28"}
2024-04-15T08:13:13 {"block_run_id": 345, "block_uuid": "trigger_pipline", "pipeline_run_id": 90, "pipeline_schedule_id": 4, "pipeline_uuid": "pipeline_manager", "hostname": "56b0cc6559da", "level": "INFO", "message": "Execute PipelineRun 90, BlockRun 345: pipeline pipeline_manager block trigger_pipline", "timestamp": 1713168793.704222, "uuid": "92044d21c1ef4444841d738e346e8de0"}
2024-04-15T08:13:15 {"block_run_id": 345, "block_uuid": "trigger_pipline", "pipeline_run_id": 90, "pipeline_schedule_id": 4, "pipeline_uuid": "pipeline_manager", "hostname": "56b0cc6559da", "level": "EXCEPTION", "message": "BlockRun 345 (block_uuid: trigger_pipline) failed.", "timestamp": 1713168795.516788, "uuid": "586ec37d5c834943ad4dbb3888bb2657", "error": ["Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/variable.py\", line 477, in __read_parquet\n    df = self.storage.read_parquet(file_path, engine='pyarrow')\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/storage/local_storage.py\", line 97, in read_parquet\n    return pd.read_parquet(file_path, engine='pyarrow')\n  File \"/usr/local/lib/python3.10/site-packages/pandas/io/parquet.py\", line 503, in read_parquet\n    return impl.read(\n  File \"/usr/local/lib/python3.10/site-packages/pandas/io/parquet.py\", line 251, in read\n    result = self.api.parquet.read_table(\n  File \"pyarrow/array.pxi\", line 884, in pyarrow.lib._PandasConvertible.to_pandas\n  File \"pyarrow/table.pxi\", line 4192, in pyarrow.lib.Table._to_pandas\n  File \"/usr/local/lib/python3.10/site-packages/pyarrow/pandas_compat.py\", line 766, in table_to_blockmanager\n    ext_columns_dtypes = _get_extension_dtypes(\n  File \"/usr/local/lib/python3.10/site-packages/pyarrow/pandas_compat.py\", line 819, in _get_extension_dtypes\n    pandas_dtype = _pandas_api.pandas_dtype(dtype)\n  File \"pyarrow/pandas-shim.pxi\", line 140, in pyarrow.lib._PandasAPIShim.pandas_dtype\n  File \"pyarrow/pandas-shim.pxi\", line 143, in pyarrow.lib._PandasAPIShim.pandas_dtype\n  File \"/usr/local/lib/python3.10/site-packages/pandas/core/dtypes/common.py\", line 1781, in pandas_dtype\n    npdtype = np.dtype(dtype)\nTypeError: data type 'dbdate' not understood\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 613, in execute\n    result = __execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py\", line 54, in retry_func\n    raise e\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py\", line 38, in retry_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 588, in __execute_with_retry\n    return self._execute(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 1077, in _execute\n    result = self.block.execute_sync(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1315, in execute_sync\n    raise err\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1224, in execute_sync\n    output = self.execute_block(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1512, in execute_block\n    self.__get_outputs_from_input_vars(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1454, in __get_outputs_from_input_vars\n    input_vars, kwargs_vars, upstream_block_uuids = self.fetch_input_variables(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1826, in fetch_input_variables\n    variables = fetch_input_variables(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/utils.py\", line 545, in fetch_input_variables\n    variable_values = [\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/utils.py\", line 546, in <listcomp>\n    pipeline.get_block_variable(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/pipeline.py\", line 1624, in get_block_variable\n    variable = block.get_variable(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1917, in get_variable\n    value = variable_manager.get_variable(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/variable_manager.py\", line 217, in get_variable\n    return variable.read_data(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/variable.py\", line 182, in read_data\n    return self.__read_parquet(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/variable.py\", line 480, in __read_parquet\n    raise Exception(f'Failed to read parquet file: {file_path}') from ex\nException: Failed to read parquet file: /home/src/mage_data/sentistocks/pipelines/pipeline_manager/.variables/4/20240415T000000/load_bigquery_state/output_0/data.parquet\n"], "error_stack": [["  File \"/usr/local/bin/mage\", line 8, in <module>\n    sys.exit(app())\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/main.py\", line 311, in __call__\n    return get_command(self)(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1130, in __call__\n    return self.main(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/core.py\", line 778, in main\n    return _main(\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/core.py\", line 216, in _main\n    rv = self.invoke(ctx)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 760, in invoke\n    return __callback(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/main.py\", line 683, in wrapper\n    return callback(**use_params)  # type: ignore\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/cli/main.py\", line 163, in start\n    start_server(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/server.py\", line 659, in start_server\n    scheduler_manager.start_scheduler()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/scheduler_manager.py\", line 87, in start_scheduler\n    proc.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/process.py\", line 15, in start_session_and_run\n    results = target(*args)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/scheduler_manager.py\", line 50, in run_scheduler\n    LoopTimeTrigger().start()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/triggers/loop_time_trigger.py\", line 14, in start\n    self.run()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/triggers/time_trigger.py\", line 11, in run\n    schedule_all()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 1610, in schedule_all\n    PipelineScheduler(r).schedule()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/__init__.py\", line 149, in func_with_rollback\n    return func(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 315, in schedule\n    self.__schedule_blocks(block_runs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 591, in __schedule_blocks\n    job_manager.add_job(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/job_manager.py\", line 27, in add_job\n    self.queue.enqueue(job_id, target, *args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 108, in enqueue\n    self.start_worker_pool()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 183, in start_worker_pool\n    self.worker_pool_proc.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 288, in poll_job_and_execute\n    worker.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/site-packages/newrelic/api/background_task.py\", line 117, in wrapper\n    return wrapped(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 253, in run\n    start_session_and_run(args[1], *args[2], **args[3])\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/process.py\", line 15, in start_session_and_run\n    results = target(*args)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 1135, in run_block\n    return ExecutorFactory.get_block_executor(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 641, in execute\n    on_failure(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/__init__.py\", line 149, in func_with_rollback\n    return func(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 422, in on_block_failure\n    self.logger.exception(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/logging/logger.py\", line 30, in exception\n    self.__send_message('exception', message, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/logging/logger.py\", line 59, in __send_message\n    data['error_stack'] = traceback.format_stack(),\n"]], "error_stacktrace": ["Failed to read parquet file: /home/src/mage_data/sentistocks/pipelines/pipeline_manager/.variables/4/20240415T000000/load_bigquery_state/output_0/data.parquet"]}
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/variable.py", line 477, in __read_parquet
    df = self.storage.read_parquet(file_path, engine='pyarrow')
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/storage/local_storage.py", line 97, in read_parquet
    return pd.read_parquet(file_path, engine='pyarrow')
  File "/usr/local/lib/python3.10/site-packages/pandas/io/parquet.py", line 503, in read_parquet
    return impl.read(
  File "/usr/local/lib/python3.10/site-packages/pandas/io/parquet.py", line 251, in read
    result = self.api.parquet.read_table(
  File "pyarrow/array.pxi", line 884, in pyarrow.lib._PandasConvertible.to_pandas
  File "pyarrow/table.pxi", line 4192, in pyarrow.lib.Table._to_pandas
  File "/usr/local/lib/python3.10/site-packages/pyarrow/pandas_compat.py", line 766, in table_to_blockmanager
    ext_columns_dtypes = _get_extension_dtypes(
  File "/usr/local/lib/python3.10/site-packages/pyarrow/pandas_compat.py", line 819, in _get_extension_dtypes
    pandas_dtype = _pandas_api.pandas_dtype(dtype)
  File "pyarrow/pandas-shim.pxi", line 140, in pyarrow.lib._PandasAPIShim.pandas_dtype
  File "pyarrow/pandas-shim.pxi", line 143, in pyarrow.lib._PandasAPIShim.pandas_dtype
  File "/usr/local/lib/python3.10/site-packages/pandas/core/dtypes/common.py", line 1781, in pandas_dtype
    npdtype = np.dtype(dtype)
TypeError: data type 'dbdate' not understood

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py", line 613, in execute
    result = __execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py", line 54, in retry_func
    raise e
  File "/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py", line 38, in retry_func
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py", line 588, in __execute_with_retry
    return self._execute(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py", line 1077, in _execute
    result = self.block.execute_sync(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1315, in execute_sync
    raise err
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1224, in execute_sync
    output = self.execute_block(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1512, in execute_block
    self.__get_outputs_from_input_vars(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1454, in __get_outputs_from_input_vars
    input_vars, kwargs_vars, upstream_block_uuids = self.fetch_input_variables(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1826, in fetch_input_variables
    variables = fetch_input_variables(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/utils.py", line 545, in fetch_input_variables
    variable_values = [
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/utils.py", line 546, in <listcomp>
    pipeline.get_block_variable(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/pipeline.py", line 1624, in get_block_variable
    variable = block.get_variable(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1917, in get_variable
    value = variable_manager.get_variable(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/variable_manager.py", line 217, in get_variable
    return variable.read_data(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/variable.py", line 182, in read_data
    return self.__read_parquet(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/variable.py", line 480, in __read_parquet
    raise Exception(f'Failed to read parquet file: {file_path}') from ex
Exception: Failed to read parquet file: /home/src/mage_data/sentistocks/pipelines/pipeline_manager/.variables/4/20240415T000000/load_bigquery_state/output_0/data.parquet
2024-04-15T08:13:21 {"cpu": 0.80810546875, "cpu_total": 8, "cpu_usage": 0.10101318359375, "memory": 1425.0, "memory_total": 4802.0, "memory_usage": 0.2967513536026656, "pipeline_run_id": 90, "pipeline_schedule_id": 4, "pipeline_uuid": "pipeline_manager", "hostname": "56b0cc6559da", "level": "INFO", "message": "Pipeline pipeline_manager for run 90 in schedule 4 is alive.", "timestamp": 1713168801.915588, "uuid": "5cf7868895a843f4bdd6ad5c43059c75"}
