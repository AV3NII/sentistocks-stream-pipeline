2024-04-13T20:19:06 {"cpu": 1.22900390625, "cpu_total": 4, "cpu_usage": 0.3072509765625, "memory": 5709.0, "memory_total": 24291.0, "memory_usage": 0.23502531801901938, "pipeline_run_id": 79, "pipeline_schedule_id": 5, "pipeline_uuid": "pipeline_manager", "hostname": "dab4364d64fd", "level": "INFO", "message": "Pipeline pipeline_manager for run 79 in schedule 5 is alive.", "timestamp": 1713039546.846423, "uuid": "6a27c923e7624acc85af02d82a6fa50c"}
2024-04-13T20:19:07 {"cpu": 1.22900390625, "cpu_total": 4, "cpu_usage": 0.3072509765625, "memory": 5748.0, "memory_total": 24291.0, "memory_usage": 0.23663085093244413, "pipeline_run_id": 79, "pipeline_schedule_id": 5, "pipeline_uuid": "pipeline_manager", "hostname": "dab4364d64fd", "level": "INFO", "message": "Pipeline pipeline_manager for run 79 in schedule 5 is alive.", "timestamp": 1713039547.14682, "uuid": "6717b506ce4c4801a9168eee471d80b4"}
2024-04-13T20:19:07 {"block_run_id": 310, "block_uuid": "load_bigquery_state", "pipeline_run_id": 79, "pipeline_schedule_id": 5, "pipeline_uuid": "pipeline_manager", "hostname": "dab4364d64fd", "level": "INFO", "message": "Execute PipelineRun 79, BlockRun 310: pipeline pipeline_manager block load_bigquery_state", "timestamp": 1713039547.231198, "uuid": "17a141a01463433699fb820db06af2f0"}
2024-04-13T20:19:11 {"block_run_id": 310, "block_uuid": "load_bigquery_state", "pipeline_run_id": 79, "pipeline_schedule_id": 5, "pipeline_uuid": "pipeline_manager", "hostname": "dab4364d64fd", "level": "INFO", "message": "BlockRun 310 (block_uuid: load_bigquery_state) completes.", "timestamp": 1713039551.267275, "uuid": "aa792fe132c941428547cdc0c396098f"}
2024-04-13T20:19:16 {"cpu": 1.22216796875, "cpu_total": 4, "cpu_usage": 0.3055419921875, "memory": 5711.0, "memory_total": 24291.0, "memory_usage": 0.23510765304022066, "pipeline_run_id": 79, "pipeline_schedule_id": 5, "pipeline_uuid": "pipeline_manager", "hostname": "dab4364d64fd", "level": "INFO", "message": "Pipeline pipeline_manager for run 79 in schedule 5 is alive.", "timestamp": 1713039556.502449, "uuid": "dab58685cee14cc68716cfb7bd145dc5"}
2024-04-13T20:19:16 {"block_run_id": 311, "block_uuid": "trigger_pipline", "pipeline_run_id": 79, "pipeline_schedule_id": 5, "pipeline_uuid": "pipeline_manager", "hostname": "dab4364d64fd", "level": "INFO", "message": "Execute PipelineRun 79, BlockRun 311: pipeline pipeline_manager block trigger_pipline", "timestamp": 1713039556.743486, "uuid": "cbddd88319ea49a99b450dc265fa2a96"}
2024-04-13T20:19:17 {"block_run_id": 311, "block_uuid": "trigger_pipline", "pipeline_run_id": 79, "pipeline_schedule_id": 5, "pipeline_uuid": "pipeline_manager", "hostname": "dab4364d64fd", "level": "EXCEPTION", "message": "BlockRun 311 (block_uuid: trigger_pipline) failed.", "timestamp": 1713039557.561026, "uuid": "5c7ed8dc0f7d4ba592e6bc3923b754e8", "error": ["Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/variable.py\", line 482, in __read_parquet\n    df = self.storage.read_parquet(file_path, engine='pyarrow')\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/storage/local_storage.py\", line 112, in read_parquet\n    return pd.read_parquet(file_path, engine='pyarrow')\n  File \"/usr/local/lib/python3.10/site-packages/pandas/io/parquet.py\", line 503, in read_parquet\n    return impl.read(\n  File \"/usr/local/lib/python3.10/site-packages/pandas/io/parquet.py\", line 251, in read\n    result = self.api.parquet.read_table(\n  File \"pyarrow/array.pxi\", line 884, in pyarrow.lib._PandasConvertible.to_pandas\n  File \"pyarrow/table.pxi\", line 4192, in pyarrow.lib.Table._to_pandas\n  File \"/usr/local/lib/python3.10/site-packages/pyarrow/pandas_compat.py\", line 766, in table_to_blockmanager\n    ext_columns_dtypes = _get_extension_dtypes(\n  File \"/usr/local/lib/python3.10/site-packages/pyarrow/pandas_compat.py\", line 819, in _get_extension_dtypes\n    pandas_dtype = _pandas_api.pandas_dtype(dtype)\n  File \"pyarrow/pandas-shim.pxi\", line 140, in pyarrow.lib._PandasAPIShim.pandas_dtype\n  File \"pyarrow/pandas-shim.pxi\", line 143, in pyarrow.lib._PandasAPIShim.pandas_dtype\n  File \"/usr/local/lib/python3.10/site-packages/pandas/core/dtypes/common.py\", line 1781, in pandas_dtype\n    npdtype = np.dtype(dtype)\nTypeError: data type 'dbdate' not understood\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 613, in execute\n    result = __execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py\", line 54, in retry_func\n    raise e\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py\", line 38, in retry_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 588, in __execute_with_retry\n    return self._execute(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 1077, in _execute\n    result = self.block.execute_sync(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1258, in execute_sync\n    raise err\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1167, in execute_sync\n    output = self.execute_block(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1455, in execute_block\n    self.__get_outputs_from_input_vars(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1397, in __get_outputs_from_input_vars\n    input_vars, kwargs_vars, upstream_block_uuids = self.fetch_input_variables(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1769, in fetch_input_variables\n    variables = fetch_input_variables(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/utils.py\", line 545, in fetch_input_variables\n    variable_values = [\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/utils.py\", line 546, in <listcomp>\n    pipeline.get_block_variable(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/pipeline.py\", line 1752, in get_block_variable\n    variable = block.get_variable(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1860, in get_variable\n    value = variable_manager.get_variable(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/variable_manager.py\", line 217, in get_variable\n    return variable.read_data(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/variable.py\", line 183, in read_data\n    return self.__read_parquet(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/variable.py\", line 485, in __read_parquet\n    raise Exception(f'Failed to read parquet file: {file_path}') from ex\nException: Failed to read parquet file: /home/src/mage_data/sentistocks/pipelines/pipeline_manager/.variables/5/20240413T201902_403029/load_bigquery_state/output_0/data.parquet\n"], "error_stack": [["  File \"/usr/local/bin/mage\", line 8, in <module>\n    sys.exit(app())\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/main.py\", line 311, in __call__\n    return get_command(self)(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1130, in __call__\n    return self.main(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/core.py\", line 778, in main\n    return _main(\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/core.py\", line 216, in _main\n    rv = self.invoke(ctx)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 760, in invoke\n    return __callback(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/main.py\", line 683, in wrapper\n    return callback(**use_params)  # type: ignore\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/cli/main.py\", line 163, in start\n    start_server(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/server.py\", line 750, in start_server\n    scheduler_manager.start_scheduler()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/scheduler_manager.py\", line 92, in start_scheduler\n    proc.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/process.py\", line 15, in start_session_and_run\n    results = target(*args)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/scheduler_manager.py\", line 53, in run_scheduler\n    LoopTimeTrigger().start()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/triggers/loop_time_trigger.py\", line 14, in start\n    self.run()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/triggers/time_trigger.py\", line 11, in run\n    schedule_all()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 1654, in schedule_all\n    PipelineScheduler(r).schedule()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/__init__.py\", line 157, in func_with_rollback\n    return func(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 318, in schedule\n    self.__schedule_blocks(block_runs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 611, in __schedule_blocks\n    job_manager.add_job(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/job_manager.py\", line 28, in add_job\n    self.queue.enqueue(job_id, target, *args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 121, in enqueue\n    self.start_worker_pool()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 198, in start_worker_pool\n    self.worker_pool_proc.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 351, in poll_job_and_execute\n    worker.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/site-packages/newrelic/api/background_task.py\", line 117, in wrapper\n    return wrapped(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 315, in run\n    start_session_and_run(args[1], *args[2], **args[3])\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/process.py\", line 15, in start_session_and_run\n    results = target(*args)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 1163, in run_block\n    return ExecutorFactory.get_block_executor(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 641, in execute\n    on_failure(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/__init__.py\", line 157, in func_with_rollback\n    return func(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 442, in on_block_failure\n    self.logger.exception(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/logging/logger.py\", line 30, in exception\n    self.__send_message('exception', message, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/logging/logger.py\", line 65, in __send_message\n    data['error_stack'] = traceback.format_stack(),\n"]], "error_stacktrace": ["Failed to read parquet file: /home/src/mage_data/sentistocks/pipelines/pipeline_manager/.variables/5/20240413T201902_403029/load_bigquery_state/output_0/data.parquet"]}
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/variable.py", line 482, in __read_parquet
    df = self.storage.read_parquet(file_path, engine='pyarrow')
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/storage/local_storage.py", line 112, in read_parquet
    return pd.read_parquet(file_path, engine='pyarrow')
  File "/usr/local/lib/python3.10/site-packages/pandas/io/parquet.py", line 503, in read_parquet
    return impl.read(
  File "/usr/local/lib/python3.10/site-packages/pandas/io/parquet.py", line 251, in read
    result = self.api.parquet.read_table(
  File "pyarrow/array.pxi", line 884, in pyarrow.lib._PandasConvertible.to_pandas
  File "pyarrow/table.pxi", line 4192, in pyarrow.lib.Table._to_pandas
  File "/usr/local/lib/python3.10/site-packages/pyarrow/pandas_compat.py", line 766, in table_to_blockmanager
    ext_columns_dtypes = _get_extension_dtypes(
  File "/usr/local/lib/python3.10/site-packages/pyarrow/pandas_compat.py", line 819, in _get_extension_dtypes
    pandas_dtype = _pandas_api.pandas_dtype(dtype)
  File "pyarrow/pandas-shim.pxi", line 140, in pyarrow.lib._PandasAPIShim.pandas_dtype
  File "pyarrow/pandas-shim.pxi", line 143, in pyarrow.lib._PandasAPIShim.pandas_dtype
  File "/usr/local/lib/python3.10/site-packages/pandas/core/dtypes/common.py", line 1781, in pandas_dtype
    npdtype = np.dtype(dtype)
TypeError: data type 'dbdate' not understood

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py", line 613, in execute
    result = __execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py", line 54, in retry_func
    raise e
  File "/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py", line 38, in retry_func
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py", line 588, in __execute_with_retry
    return self._execute(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py", line 1077, in _execute
    result = self.block.execute_sync(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1258, in execute_sync
    raise err
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1167, in execute_sync
    output = self.execute_block(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1455, in execute_block
    self.__get_outputs_from_input_vars(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1397, in __get_outputs_from_input_vars
    input_vars, kwargs_vars, upstream_block_uuids = self.fetch_input_variables(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1769, in fetch_input_variables
    variables = fetch_input_variables(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/utils.py", line 545, in fetch_input_variables
    variable_values = [
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/utils.py", line 546, in <listcomp>
    pipeline.get_block_variable(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/pipeline.py", line 1752, in get_block_variable
    variable = block.get_variable(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1860, in get_variable
    value = variable_manager.get_variable(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/variable_manager.py", line 217, in get_variable
    return variable.read_data(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/variable.py", line 183, in read_data
    return self.__read_parquet(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/variable.py", line 485, in __read_parquet
    raise Exception(f'Failed to read parquet file: {file_path}') from ex
Exception: Failed to read parquet file: /home/src/mage_data/sentistocks/pipelines/pipeline_manager/.variables/5/20240413T201902_403029/load_bigquery_state/output_0/data.parquet
2024-04-13T20:19:26 {"cpu": 1.21240234375, "cpu_total": 4, "cpu_usage": 0.3031005859375, "memory": 5714.0, "memory_total": 24291.0, "memory_usage": 0.23523115557202257, "pipeline_run_id": 79, "pipeline_schedule_id": 5, "pipeline_uuid": "pipeline_manager", "hostname": "dab4364d64fd", "level": "INFO", "message": "Pipeline pipeline_manager for run 79 in schedule 5 is alive.", "timestamp": 1713039566.925245, "uuid": "8e08b2f4aa58453199326f0b1c32f68f"}
